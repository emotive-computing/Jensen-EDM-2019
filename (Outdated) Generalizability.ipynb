{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data of 5-minute windows preceding survey responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyfile = '../Data (Algebra 1)/YearSurvey.csv'\n",
    "featuredf = readData(surveyfile)\n",
    "featuredf = dropColumns(featuredf,['survey_id','time_window','question_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import demographic file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "demofile = '../Data (Algebra 1)/YearDemographicsTest.csv'\n",
    "demodf = readData(demofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter so survey and demographic files have the same indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodf = filterByIndex(demodf,featuredf.index)\n",
    "featuredfA = filterByIndex(featuredf,demodf.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Happiness','Frustration','Confusion','Hopefulness','Contentment',\n",
    "         'Disappointment','Relief','Pride','Pleasantness','Anxiety','Engagement',\n",
    "         'Interest','Sadness','Mind Wandering','Boredom','Arousal',\n",
    "         'Curiosity','Surprise']\n",
    "nStates = len(states)\n",
    "nFolds = 10\n",
    "kfold = GroupKFold(n_splits = nFolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Male/Female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide female and male students in the demographic file and filter survey file accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaleind = demodf.loc[demodf['Female'] == 1].index\n",
    "featuredfF = filterByIndex(featuredf,femaleind)\n",
    "\n",
    "maleind = demodf.loc[demodf['Female'] == 0].index\n",
    "featuredfM = filterByIndex(featuredf,maleind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifiers on male/female/all, and predict for male/female/all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresF = np.zeros((nStates,3))\n",
    "scoresM = scoresF.copy()\n",
    "scoresA = scoresF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for each state\n",
    "for s in range(nStates):\n",
    "    # Get data for that state\n",
    "    featuresM, labelsM = filterByState(states[s],featuredfM)\n",
    "    featuresM = featuresM.values\n",
    "    labelsM = labelsM.values\n",
    "    featuresF, labelsF = filterByState(states[s],featuredfF)\n",
    "    featuresF = featuresF.values\n",
    "    labelsF = labelsF.values\n",
    "    featuresA, labelsA = filterByState(states[s],featuredfA)\n",
    "    featuresA = featuresA.values\n",
    "    labelsA = labelsA.values\n",
    "    \n",
    "    # Repeat for k folds (Male)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,3))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresM,labelsM)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresM[train],labelsM[train],featuresM[test])\n",
    "        # Predict Female\n",
    "        predF = model.predict(featuresF)\n",
    "        rhoF = evaluateSpearman(labelsF,predF)\n",
    "        temp[i,0] = rhoF\n",
    "        # Predict Male\n",
    "        predM = model.predict(featuresM)\n",
    "        rhoM = evaluateSpearman(labelsM,predM)\n",
    "        temp[i,1] = rhoM\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,2] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresF[s,0] = avg[0]\n",
    "    scoresM[s,0] = avg[1]\n",
    "    scoresA[s,0] = avg[2]\n",
    "    \n",
    "    # Repeat for k folds (Female)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,3))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresF,labelsF)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresF[train],labelsF[train],featuresF[test])\n",
    "        # Predict Female\n",
    "        predF = model.predict(featuresF)\n",
    "        rhoF = evaluateSpearman(labelsF,predF)\n",
    "        temp[i,0] = rhoF\n",
    "        # Predict Male\n",
    "        predM = model.predict(featuresM)\n",
    "        rhoM = evaluateSpearman(labelsM,predM)\n",
    "        temp[i,1] = rhoM\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,2] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresF[s,1] = avg[0]\n",
    "    scoresM[s,1] = avg[1]\n",
    "    scoresA[s,1] = avg[2]\n",
    "    \n",
    "    # Repeat for k folds (All)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,3))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresA,labelsA)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresA[train],labelsA[train],featuresA[test])\n",
    "        # Predict Female\n",
    "        predF = model.predict(featuresF)\n",
    "        rhoF = evaluateSpearman(labelsF,predF)\n",
    "        temp[i,0] = rhoF\n",
    "        # Predict Male\n",
    "        predM = model.predict(featuresM)\n",
    "        rhoM = evaluateSpearman(labelsM,predM)\n",
    "        temp[i,1] = rhoM\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,2] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresF[s,2] = avg[0]\n",
    "    scoresM[s,2] = avg[1]\n",
    "    scoresA[s,2] = avg[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Train Male','Train Female','Train All']\n",
    "dfF = pd.DataFrame(data=scoresF,index=states,columns=columns)\n",
    "dfF['Mean'] = dfF.mean(axis=1)\n",
    "avg = dfF.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfF = dfF.append(avg)\n",
    "dfM = pd.DataFrame(data=scoresM,index=states,columns=columns)\n",
    "dfM['Mean'] = dfM.mean(axis=1)\n",
    "avg = dfM.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfM = dfM.append(avg)\n",
    "dfA = pd.DataFrame(data=scoresA,index=states,columns=columns)\n",
    "dfA['Mean'] = dfA.mean(axis=1)\n",
    "avg = dfA.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfA = dfA.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfF.to_csv('../Data (Algebra 1)/gender scores female.csv')\n",
    "dfM.to_csv('../Data (Algebra 1)/gender scores male.csv')\n",
    "dfA.to_csv('../Data (Algebra 1)/gender scores all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lunch Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide students by lunch status in the demographic file and filter survey file accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeind = demodf.loc[demodf['Free Lunch'] == 1].index\n",
    "featuredfF = filterByIndex(featuredf,freeind)\n",
    "\n",
    "reducedind = demodf.loc[demodf['Reduced Lunch'] == 1].index\n",
    "featuredfR = filterByIndex(featuredf,reducedind)\n",
    "\n",
    "otherind = demodf.loc[demodf['Other Lunch'] == 1].index\n",
    "featuredfO = filterByIndex(featuredf,otherind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifiers on free/reduced/other/all, and predict for free/reduced/other/all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresF = np.zeros((nStates,4))\n",
    "scoresR = scoresF.copy()\n",
    "scoresO = scoresF.copy()\n",
    "scoresA = scoresF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for each state\n",
    "for s in range(nStates):\n",
    "    # Get data for that state\n",
    "    featuresF, labelsF = filterByState(states[s],featuredfF)\n",
    "    featuresF = featuresF.values\n",
    "    labelsF = labelsF.values\n",
    "    featuresR, labelsR = filterByState(states[s],featuredfR)\n",
    "    featuresR = featuresR.values\n",
    "    labelsR = labelsR.values\n",
    "    featuresO, labelsO = filterByState(states[s],featuredfO)\n",
    "    featuresO = featuresO.values\n",
    "    labelsO = labelsO.values\n",
    "    featuresA, labelsA = filterByState(states[s],featuredfA)\n",
    "    featuresA = featuresA.values\n",
    "    labelsA = labelsA.values\n",
    "    \n",
    "    # Repeat for k folds (Free)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,4))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresF,labelsF)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresF[train],labelsF[train],featuresF[test])\n",
    "        # Predict Free\n",
    "        predF = model.predict(featuresF)\n",
    "        rhoF = evaluateSpearman(labelsF,predF)\n",
    "        temp[i,0] = rhoF\n",
    "        # Predict Reduced\n",
    "        predR = model.predict(featuresR)\n",
    "        rhoR = evaluateSpearman(labelsR,predR)\n",
    "        temp[i,1] = rhoR\n",
    "        # Predict Other\n",
    "        predO = model.predict(featuresO)\n",
    "        rhoO = evaluateSpearman(labelsO,predO)\n",
    "        temp[i,2] = rhoO\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,3] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresF[s,0] = avg[0]\n",
    "    scoresR[s,0] = avg[1]\n",
    "    scoresO[s,0] = avg[2]\n",
    "    scoresA[s,0] = avg[3]\n",
    "    \n",
    "    # Repeat for k folds (Reduced)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,4))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresR,labelsR)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresR[train],labelsR[train],featuresR[test])\n",
    "        # Predict Free\n",
    "        predF = model.predict(featuresF)\n",
    "        rhoF = evaluateSpearman(labelsF,predF)\n",
    "        temp[i,0] = rhoF\n",
    "        # Predict Reduced\n",
    "        predR = model.predict(featuresR)\n",
    "        rhoR = evaluateSpearman(labelsR,predR)\n",
    "        temp[i,1] = rhoR\n",
    "        # Predict Other\n",
    "        predO = model.predict(featuresO)\n",
    "        rhoO = evaluateSpearman(labelsO,predO)\n",
    "        temp[i,2] = rhoO\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,3] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresF[s,1] = avg[0]\n",
    "    scoresR[s,1] = avg[1]\n",
    "    scoresO[s,1] = avg[2]\n",
    "    scoresA[s,1] = avg[3]\n",
    "    \n",
    "    # Repeat for k folds (Other)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,4))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresO,labelsO)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresO[train],labelsO[train],featuresO[test])\n",
    "        # Predict Free\n",
    "        predF = model.predict(featuresF)\n",
    "        rhoF = evaluateSpearman(labelsF,predF)\n",
    "        temp[i,0] = rhoF\n",
    "        # Predict Reduced\n",
    "        predR = model.predict(featuresR)\n",
    "        rhoR = evaluateSpearman(labelsR,predR)\n",
    "        temp[i,1] = rhoR\n",
    "        # Predict Other\n",
    "        predO = model.predict(featuresO)\n",
    "        rhoO = evaluateSpearman(labelsO,predO)\n",
    "        temp[i,2] = rhoO\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,3] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresF[s,2] = avg[0]\n",
    "    scoresR[s,2] = avg[1]\n",
    "    scoresO[s,2] = avg[2]\n",
    "    scoresA[s,2] = avg[3]\n",
    "    \n",
    "    # Repeat for k folds (All)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,4))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresA,labelsA)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresA[train],labelsA[train],featuresA[test])\n",
    "        # Predict Free\n",
    "        predF = model.predict(featuresF)\n",
    "        rhoF = evaluateSpearman(labelsF,predF)\n",
    "        temp[i,0] = rhoF\n",
    "        # Predict Reduced\n",
    "        predR = model.predict(featuresR)\n",
    "        rhoR = evaluateSpearman(labelsR,predR)\n",
    "        temp[i,1] = rhoR\n",
    "        # Predict Other\n",
    "        predO = model.predict(featuresO)\n",
    "        rhoO = evaluateSpearman(labelsO,predO)\n",
    "        temp[i,2] = rhoO\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,3] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresF[s,3] = avg[0]\n",
    "    scoresR[s,3] = avg[1]\n",
    "    scoresO[s,3] = avg[2]\n",
    "    scoresA[s,3] = avg[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Train Free','Train Reduced','Train Other','Train All']\n",
    "dfF = pd.DataFrame(data=scoresF,index=states,columns=columns)\n",
    "dfF['Mean'] = dfF.mean(axis=1)\n",
    "avg = dfF.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfF = dfF.append(avg)\n",
    "dfR = pd.DataFrame(data=scoresR,index=states,columns=columns)\n",
    "dfR['Mean'] = dfR.mean(axis=1)\n",
    "avg = dfR.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfR = dfR.append(avg)\n",
    "dfO = pd.DataFrame(data=scoresO,index=states,columns=columns)\n",
    "dfO['Mean'] = dfO.mean(axis=1)\n",
    "avg = dfO.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfO = dfO.append(avg)\n",
    "dfA = pd.DataFrame(data=scoresA,index=states,columns=columns)\n",
    "dfA['Mean'] = dfA.mean(axis=1)\n",
    "avg = dfA.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfA = dfA.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfO.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfF.to_csv('../Data (Algebra 1)/lunch scores free.csv')\n",
    "dfR.to_csv('../Data (Algebra 1)/lunch scores reduced.csv')\n",
    "dfO.to_csv('../Data (Algebra 1)/lunch scores other.csv')\n",
    "dfA.to_csv('../Data (Algebra 1)/lunch scores all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grade level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide middle school and high school students in the demographic file and filter survey file accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "middleind = pd.concat([demodf.loc[demodf['Grade 6'] == 1],demodf.loc[demodf['Grade 7'] == 1],\n",
    "                       demodf.loc[demodf['Grade 8'] == 1]]).sort_index().index\n",
    "featuredfM = filterByIndex(featuredf,middleind)\n",
    "\n",
    "highind = pd.concat([demodf.loc[demodf['Grade 9'] == 1],demodf.loc[demodf['Grade 10'] == 1],\n",
    "                     demodf.loc[demodf['Grade 11'] == 1],demodf.loc[demodf['Grade 12'] == 1]]).sort_index().index\n",
    "featuredfH = filterByIndex(featuredf,highind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifiers on middle/high/all, and predict for middle/high/all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresM = np.zeros((nStates,3))\n",
    "scoresH = scoresM.copy()\n",
    "scoresA = scoresM.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for each state\n",
    "for s in range(nStates):\n",
    "    # Get data for that state\n",
    "    featuresM, labelsM = filterByState(states[s],featuredfM)\n",
    "    featuresM = featuresM.values\n",
    "    labelsM = labelsM.values\n",
    "    featuresH, labelsH = filterByState(states[s],featuredfH)\n",
    "    featuresH = featuresH.values\n",
    "    labelsH = labelsH.values\n",
    "    featuresA, labelsA = filterByState(states[s],featuredfA)\n",
    "    featuresA = featuresA.values\n",
    "    labelsA = labelsA.values\n",
    "    \n",
    "    # Repeat for k folds (Middle school)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,3))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresM,labelsM)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresM[train],labelsM[train],featuresM[test])\n",
    "        # Predict Middle school\n",
    "        predM = model.predict(featuresM)\n",
    "        rhoM = evaluateSpearman(labelsM,predM)\n",
    "        temp[i,0] = rhoM\n",
    "        # Predict High school\n",
    "        predH = model.predict(featuresH)\n",
    "        rhoH = evaluateSpearman(labelsH,predH)\n",
    "        temp[i,1] = rhoH\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,2] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresM[s,0] = avg[0]\n",
    "    scoresH[s,0] = avg[1]\n",
    "    scoresA[s,0] = avg[2]\n",
    "    \n",
    "    # Repeat for k folds (High school)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,3))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresH,labelsH)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresH[train],labelsH[train],featuresH[test])\n",
    "        # Predict Middle school\n",
    "        predM = model.predict(featuresM)\n",
    "        rhoM = evaluateSpearman(labelsM,predM)\n",
    "        temp[i,0] = rhoM\n",
    "        # Predict High school\n",
    "        predH = model.predict(featuresH)\n",
    "        rhoH = evaluateSpearman(labelsH,predH)\n",
    "        temp[i,1] = rhoH\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,2] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresM[s,1] = avg[0]\n",
    "    scoresH[s,1] = avg[1]\n",
    "    scoresA[s,1] = avg[2]\n",
    "    \n",
    "    # Repeat for k folds (All)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,3))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresA,labelsA)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresA[train],labelsA[train],featuresA[test])\n",
    "        # Predict Middle school\n",
    "        predM = model.predict(featuresM)\n",
    "        rhoM = evaluateSpearman(labelsM,predM)\n",
    "        temp[i,0] = rhoM\n",
    "        # Predict High school\n",
    "        predH = model.predict(featuresH)\n",
    "        rhoH = evaluateSpearman(labelsH,predH)\n",
    "        temp[i,1] = rhoH\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,2] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresM[s,2] = avg[0]\n",
    "    scoresH[s,2] = avg[1]\n",
    "    scoresA[s,2] = avg[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Train Middle','Train High','Train All']\n",
    "dfM = pd.DataFrame(data=scoresM,index=states,columns=columns)\n",
    "dfM['Mean'] = dfM.mean(axis=1)\n",
    "avg = dfM.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfM = dfM.append(avg)\n",
    "dfH = pd.DataFrame(data=scoresH,index=states,columns=columns)\n",
    "dfH['Mean'] = dfH.mean(axis=1)\n",
    "avg = dfH.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfH = dfH.append(avg)\n",
    "dfA = pd.DataFrame(data=scoresA,index=states,columns=columns)\n",
    "dfA['Mean'] = dfA.mean(axis=1)\n",
    "avg = dfA.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfA = dfA.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfH.to_csv('../Data (Algebra 1)/grade scores high school.csv')\n",
    "dfM.to_csv('../Data (Algebra 1)/grade scores middle school.csv')\n",
    "dfA.to_csv('../Data (Algebra 1)/grade scores all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race/ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide students by race/ethnicity in the demographic file and filter survey file accordingly. Due to small sample sizes, we will only consider white/black/hispanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiteind = demodf.loc[demodf['White'] == 1].index\n",
    "featuredfW = filterByIndex(featuredf,whiteind)\n",
    "\n",
    "blackind = demodf.loc[demodf['Black'] == 1].index\n",
    "featuredfB = filterByIndex(featuredf,blackind)\n",
    "\n",
    "hispind = demodf.loc[demodf['Hispanic'] == 1].index\n",
    "featuredfH = filterByIndex(featuredf,hispind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifiers on white/black/hispanic/all, and predict for white/black/hispanic/all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresW = np.zeros((nStates,4))\n",
    "scoresB = scoresW.copy()\n",
    "scoresH = scoresW.copy()\n",
    "scoresA = scoresW.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for each state\n",
    "for s in range(nStates):\n",
    "    # Get data for that state\n",
    "    featuresW, labelsW = filterByState(states[s],featuredfW)\n",
    "    featuresW = featuresW.values\n",
    "    labelsW = labelsW.values\n",
    "    featuresB, labelsB = filterByState(states[s],featuredfB)\n",
    "    featuresB = featuresB.values\n",
    "    labelsB = labelsB.values\n",
    "    featuresH, labelsH = filterByState(states[s],featuredfH)\n",
    "    featuresH = featuresH.values\n",
    "    labelsH = labelsH.values\n",
    "    featuresA, labelsA = filterByState(states[s],featuredfA)\n",
    "    featuresA = featuresA.values\n",
    "    labelsA = labelsA.values\n",
    "    \n",
    "    # Repeat for k folds (White)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,4))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresW,labelsW)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresW[train],labelsW[train],featuresW[test])\n",
    "        # Predict White\n",
    "        predW = model.predict(featuresW)\n",
    "        rhoW = evaluateSpearman(labelsW,predW)\n",
    "        temp[i,0] = rhoW\n",
    "        # Predict Black\n",
    "        predB = model.predict(featuresB)\n",
    "        rhoB = evaluateSpearman(labelsB,predB)\n",
    "        temp[i,1] = rhoB\n",
    "        # Predict Hispanic\n",
    "        predH = model.predict(featuresH)\n",
    "        rhoH = evaluateSpearman(labelsH,predH)\n",
    "        temp[i,2] = rhoH\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,3] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresW[s,0] = avg[0]\n",
    "    scoresB[s,0] = avg[1]\n",
    "    scoresH[s,0] = avg[2]\n",
    "    scoresA[s,0] = avg[3]\n",
    "    \n",
    "    # Repeat for k folds (Black)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,4))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresB,labelsB)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresB[train],labelsB[train],featuresB[test])\n",
    "        # Predict White\n",
    "        predW = model.predict(featuresW)\n",
    "        rhoW = evaluateSpearman(labelsW,predW)\n",
    "        temp[i,0] = rhoW\n",
    "        # Predict Black\n",
    "        predB = model.predict(featuresB)\n",
    "        rhoB = evaluateSpearman(labelsB,predB)\n",
    "        temp[i,1] = rhoB\n",
    "        # Predict Hispanic\n",
    "        predH = model.predict(featuresH)\n",
    "        rhoH = evaluateSpearman(labelsH,predH)\n",
    "        temp[i,2] = rhoH\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,3] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresW[s,1] = avg[0]\n",
    "    scoresB[s,1] = avg[1]\n",
    "    scoresH[s,1] = avg[2]\n",
    "    scoresA[s,1] = avg[3]\n",
    "    \n",
    "    # Repeat for k folds (Hispanic)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,4))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresH,labelsH)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresH[train],labelsH[train],featuresH[test])\n",
    "        # Predict White\n",
    "        predW = model.predict(featuresW)\n",
    "        rhoW = evaluateSpearman(labelsW,predW)\n",
    "        temp[i,0] = rhoW\n",
    "        # Predict Black\n",
    "        predB = model.predict(featuresB)\n",
    "        rhoB = evaluateSpearman(labelsB,predB)\n",
    "        temp[i,1] = rhoB\n",
    "        # Predict Hispanic\n",
    "        predH = model.predict(featuresH)\n",
    "        rhoH = evaluateSpearman(labelsH,predH)\n",
    "        temp[i,2] = rhoH\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,3] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresW[s,2] = avg[0]\n",
    "    scoresB[s,2] = avg[1]\n",
    "    scoresH[s,2] = avg[2]\n",
    "    scoresA[s,2] = avg[3]\n",
    "    \n",
    "    # Repeat for k folds (All)\n",
    "    # Set up temporary scores\n",
    "    temp = np.zeros((nFolds,4))\n",
    "    for i, (train, test) in enumerate(kfold.split(featuresA,labelsA)):\n",
    "        # Train a model\n",
    "        _, model = classify(featuresA[train],labelsA[train],featuresA[test])\n",
    "        # Predict White\n",
    "        predW = model.predict(featuresW)\n",
    "        rhoW = evaluateSpearman(labelsW,predW)\n",
    "        temp[i,0] = rhoW\n",
    "        # Predict Black\n",
    "        predB = model.predict(featuresB)\n",
    "        rhoB = evaluateSpearman(labelsB,predB)\n",
    "        temp[i,1] = rhoB\n",
    "        # Predict Hispanic\n",
    "        predH = model.predict(featuresH)\n",
    "        rhoH = evaluateSpearman(labelsH,predH)\n",
    "        temp[i,2] = rhoH\n",
    "        # Predict All\n",
    "        predA = model.predict(featuresA)\n",
    "        rhoA = evaluateSpearman(labelsA,predA)\n",
    "        temp[i,3] = rhoA\n",
    "    # Average across folds\n",
    "    avg = np.mean(temp,axis=0)\n",
    "    # Store results\n",
    "    scoresW[s,3] = avg[0]\n",
    "    scoresB[s,3] = avg[1]\n",
    "    scoresH[s,3] = avg[2]\n",
    "    scoresA[s,3] = avg[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Train White','Train Black','Train Hispanic','Train All']\n",
    "dfW = pd.DataFrame(data=scoresW,index=states,columns=columns)\n",
    "dfW['Mean'] = dfW.mean(axis=1)\n",
    "avg = dfW.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfW = dfW.append(avg)\n",
    "dfB = pd.DataFrame(data=scoresB,index=states,columns=columns)\n",
    "dfB['Mean'] = dfB.mean(axis=1)\n",
    "avg = dfB.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfB = dfB.append(avg)\n",
    "dfH = pd.DataFrame(data=scoresH,index=states,columns=columns)\n",
    "dfH['Mean'] = dfH.mean(axis=1)\n",
    "avg = dfH.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfH = dfH.append(avg)\n",
    "dfA = pd.DataFrame(data=scoresA,index=states,columns=columns)\n",
    "dfA['Mean'] = dfA.mean(axis=1)\n",
    "avg = dfA.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfA = dfA.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train White</th>\n",
       "      <th>Train Black</th>\n",
       "      <th>Train Hispanic</th>\n",
       "      <th>Train All</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Happiness</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frustration</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Confusion</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hopefulness</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contentment</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disappointment</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relief</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pride</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleasantness</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anxiety</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engagement</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interest</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sadness</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mind Wandering</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boredom</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arousal</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curiosity</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surprise</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Train White  Train Black  Train Hispanic  Train All  Mean\n",
       "Happiness              0.29         0.28            0.29       0.30  0.29\n",
       "Frustration            0.29         0.27            0.27       0.29  0.28\n",
       "Confusion              0.31         0.30            0.30       0.31  0.30\n",
       "Hopefulness            0.28         0.28            0.27       0.28  0.28\n",
       "Contentment            0.30         0.30            0.30       0.30  0.30\n",
       "Disappointment         0.29         0.27            0.28       0.29  0.28\n",
       "Relief                 0.27         0.26            0.26       0.27  0.27\n",
       "Pride                  0.27         0.27            0.27       0.27  0.27\n",
       "Pleasantness           0.25         0.24            0.24       0.25  0.25\n",
       "Anxiety                0.23         0.21            0.22       0.23  0.22\n",
       "Engagement             0.21         0.19            0.19       0.21  0.20\n",
       "Interest               0.20         0.19            0.20       0.20  0.20\n",
       "Sadness                0.18         0.16            0.18       0.18  0.18\n",
       "Mind Wandering         0.16         0.15            0.15       0.16  0.16\n",
       "Boredom                0.14         0.14            0.13       0.14  0.14\n",
       "Arousal                0.12         0.10            0.11       0.12  0.11\n",
       "Curiosity              0.10         0.04            0.07       0.10  0.08\n",
       "Surprise               0.09         0.03            0.01       0.09  0.06\n",
       "Mean                   0.22         0.20            0.21       0.22  0.21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfA.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfW.to_csv('../Data (Algebra 1)/race scores white.csv')\n",
    "dfB.to_csv('../Data (Algebra 1)/race scores black.csv')\n",
    "dfH.to_csv('../Data (Algebra 1)/race scores hispanic.csv')\n",
    "dfA.to_csv('../Data (Algebra 1)/race scores all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive/Negative affect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter surveys according to positive or negative affective states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuredfP = pd.concat([featuredfA.loc[featuredfA['survey_question']=='Happiness'],featuredfA.loc[featuredfA['survey_question']=='Hopefulness'],\n",
    "                       featuredfA.loc[featuredfA['survey_question']=='Contentment'],featuredfA.loc[featuredfA['survey_question']=='Relief'],\n",
    "                       featuredfA.loc[featuredfA['survey_question']=='Pride'],featuredfA.loc[featuredfA['survey_question']=='Pleasantness'],\n",
    "                       featuredfA.loc[featuredfA['survey_question']=='Interest'],featuredfA.loc[featuredfA['survey_question']=='Arousal'],\n",
    "                       featuredfA.loc[featuredfA['survey_question']=='Engagement']]).sort_index()\n",
    "featuredfN = pd.concat([featuredfA.loc[featuredfA['survey_question']=='Frustration'],featuredfA.loc[featuredfA['survey_question']=='Confusion'],\n",
    "                       featuredfA.loc[featuredfA['survey_question']=='Disappointment'],featuredfA.loc[featuredfA['survey_question']=='Anxiety'],\n",
    "                       featuredfA.loc[featuredfA['survey_question']=='Sadness'],featuredfA.loc[featuredfA['survey_question']=='Mind Wandering'],\n",
    "                       featuredfA.loc[featuredfA['survey_question']=='Boredom']]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsP = featuredfP['survey_answer'].values\n",
    "featuresP = dropColumns(featuredfP,['survey_answer','survey_question']).values\n",
    "\n",
    "labelsN = featuredfN['survey_answer'].values\n",
    "featuresN = dropColumns(featuredfN,['survey_answer','survey_question']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "statesP = ['Happiness','Hopefulness','Contentment','Relief',\n",
    "          'Pride','Pleasantness','Interest','Arousal','Engagement']\n",
    "statesN = ['Frustration','Confusion','Disappointment','Anxiety',\n",
    "          'Sadness','Mind Wandering','Boredom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresPP = np.zeros((len(statesP),nFolds))\n",
    "scoresNP = scoresPP.copy()\n",
    "scoresNN = np.zeros((len(statesN),nFolds))\n",
    "scoresPN = scoresNN.copy()\n",
    "\n",
    "# Repeat for k folds (Positive)\n",
    "for i, (train, test) in enumerate(kfold.split(featuresP,labelsP)):\n",
    "    \n",
    "    # Train positive model\n",
    "    _,model = classify(featuresP[train],labelsP[train],featuresP[test])\n",
    "    \n",
    "    # Predict for each positive state\n",
    "    for s in range(len(statesP)):\n",
    "        featuresS, labelsS = filterByState(statesP[s],featuredfP)\n",
    "        featuresS = featuresS.values\n",
    "        labelsS = labelsS.values\n",
    "        predS = model.predict(featuresS)\n",
    "        rhoS = evaluateSpearman(labelsS,predS)\n",
    "        scoresPP[s,i] = rhoS\n",
    "        \n",
    "    # Predict for each negative state\n",
    "    for s in range(len(statesN)):\n",
    "        featuresS, labelsS = filterByState(statesN[s],featuredfN)\n",
    "        featuresS = featuresS.values\n",
    "        labelsS = labelsS.values\n",
    "        predS = model.predict(featuresS)\n",
    "        rhoS = evaluateSpearman(labelsS,predS)\n",
    "        scoresPN[s,i] = rhoS\n",
    "        \n",
    "# Repeat for k folds (Negative)\n",
    "for i, (train, test) in enumerate(kfold.split(featuresN,labelsN)):\n",
    "    \n",
    "    # Train negative model\n",
    "    _,model = classify(featuresN[train],labelsN[train],featuresN[test])\n",
    "    \n",
    "    # Predict for each negative state\n",
    "    for s in range(len(statesN)):\n",
    "        featuresS, labelsS = filterByState(statesN[s],featuredfN)\n",
    "        featuresS = featuresS.values\n",
    "        labelsS = labelsS.values\n",
    "        predS = model.predict(featuresS)\n",
    "        rhoS = evaluateSpearman(labelsS,predS)\n",
    "        scoresNN[s,i] = rhoS\n",
    "        \n",
    "    # Predict for each positive state\n",
    "    for s in range(len(statesP)):\n",
    "        featuresS, labelsS = filterByState(statesP[s],featuredfP)\n",
    "        featuresS = featuresS.values\n",
    "        labelsS = labelsS.values\n",
    "        predS = model.predict(featuresS)\n",
    "        rhoS = evaluateSpearman(labelsS,predS)\n",
    "        scoresNP[s,i] = rhoS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfP = pd.DataFrame(data = np.mean(scoresPP,axis=1),index=statesP,columns=['Train Positive'])\n",
    "dfP['Train States'] = [0.28,0.27,0.29,0.26,0.27,0.24,0.20,0.13,0.21]\n",
    "dfP['Train Negative'] = np.mean(scoresNP,axis=1)\n",
    "dfN = pd.DataFrame(data = np.mean(scoresNN,axis=1),index=statesN,columns=['Train Negative'])\n",
    "dfN['Train States'] = [0.28,0.28,0.28,0.20,0.17,0.16,0.14]\n",
    "dfN['Train Positive'] = np.mean(scoresPN,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = dfP.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfP = dfP.append(avg)\n",
    "avg = dfN.mean(axis=0)\n",
    "avg.name = 'Mean'\n",
    "dfN = dfN.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Negative</th>\n",
       "      <th>Train States</th>\n",
       "      <th>Train Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Frustration</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Confusion</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disappointment</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anxiety</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sadness</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mind Wandering</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boredom</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Train Negative  Train States  Train Positive\n",
       "Frustration               0.28          0.28           -0.28\n",
       "Confusion                 0.31          0.28           -0.30\n",
       "Disappointment            0.28          0.28           -0.27\n",
       "Anxiety                   0.21          0.20           -0.20\n",
       "Sadness                   0.18          0.17           -0.17\n",
       "Mind Wandering            0.14          0.16           -0.14\n",
       "Boredom                   0.14          0.14           -0.13\n",
       "Mean                      0.22          0.22           -0.21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfN.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfP.to_csv('../Data (Algebra 1)/scores positive.csv')\n",
    "dfN.to_csv('../Data (Algebra 1)/scores negative.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
